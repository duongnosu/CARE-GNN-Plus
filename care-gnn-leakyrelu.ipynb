{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bffeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da665d4a",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a3aed",
   "metadata": {},
   "source": [
    "### Inter Relation Aggregator using GNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40308a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterAgg_leaky(nn.Module):\n",
    "\n",
    "\tdef __init__(self, features, feature_dim,\n",
    "\t\t\t\t embed_dim, adj_lists, intraggs,\n",
    "\t\t\t\t inter='GNN', step_size=0.02, cuda=True):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize the inter-relation aggregator\n",
    "\t\t:param features: the input node features or embeddings for all nodes\n",
    "\t\t:param feature_dim: the input dimension\n",
    "\t\t:param embed_dim: the output dimension\n",
    "\t\t:param adj_lists: a list of adjacency lists for each single-relation graph\n",
    "\t\t:param intraggs: the intra-relation aggregators used by each single-relation graph\n",
    "\t\t:param inter: the aggregator type: 'Att', 'Weight', 'Mean', 'GNN'\n",
    "\t\t:param step_size: the RL action step size\n",
    "\t\t:param cuda: whether to use GPU\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(InterAgg_leaky, self).__init__()\n",
    "\n",
    "\t\tself.features = features\n",
    "\t\tself.dropout = 0.6\n",
    "\t\tself.adj_lists = adj_lists\n",
    "\t\tself.intra_agg1 = intraggs[0]\n",
    "\t\tself.intra_agg2 = intraggs[1]\n",
    "\t\tself.intra_agg3 = intraggs[2]\n",
    "\t\tself.embed_dim = embed_dim\n",
    "\t\tself.feat_dim = feature_dim\n",
    "\t\tself.inter = inter\n",
    "\t\tself.step_size = step_size\n",
    "\t\tself.cuda = cuda\n",
    "\t\tself.intra_agg1.cuda = cuda\n",
    "\t\tself.intra_agg2.cuda = cuda\n",
    "\t\tself.intra_agg3.cuda = cuda\n",
    "\n",
    "\t\t# RL condition flag\n",
    "\t\tself.RL = True\n",
    "\n",
    "\t\t# number of batches for current epoch, assigned during training\n",
    "\t\tself.batch_num = 0\n",
    "\n",
    "\t\t# initial filtering thresholds\n",
    "\t\tself.thresholds = [0.5, 0.5, 0.5]\n",
    "\n",
    "\t\t# the activation function used by attention mechanism\n",
    "\t\tself.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "\t\t# parameter used to transform node embeddings before inter-relation aggregation\n",
    "\t\tself.weight = nn.Parameter(torch.FloatTensor(self.feat_dim, self.embed_dim))\n",
    "\t\tinit.xavier_uniform_(self.weight)\n",
    "\n",
    "\t\t# weight parameter for each relation used by CARE-Weight\n",
    "\t\tself.alpha = nn.Parameter(torch.FloatTensor(self.embed_dim, 3))\n",
    "\t\tinit.xavier_uniform_(self.alpha)\n",
    "\n",
    "\t\t# parameters used by attention layer\n",
    "\t\tself.a = nn.Parameter(torch.FloatTensor(2 * self.embed_dim, 1))\n",
    "\t\tinit.xavier_uniform_(self.a)\n",
    "\n",
    "\t\t# label predictor for similarity measure\n",
    "\t\tself.label_clf = nn.Linear(self.feat_dim, 2)\n",
    "\n",
    "\t\t# initialize the parameter logs\n",
    "\t\tself.weights_log = []\n",
    "\t\tself.thresholds_log = [self.thresholds]\n",
    "\t\tself.relation_score_log = []\n",
    "\n",
    "\tdef forward(self, nodes, labels, train_flag=True):\n",
    "\t\t\"\"\"\n",
    "\t\t:param nodes: a list of batch node ids\n",
    "\t\t:param labels: a list of batch node labels, only used by the RLModule\n",
    "\t\t:param train_flag: indicates whether in training or testing mode\n",
    "\t\t:return combined: the embeddings of a batch of input node features\n",
    "\t\t:return center_scores: the label-aware scores of batch nodes\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# extract 1-hop neighbor ids from adj lists of each single-relation graph\n",
    "\t\tto_neighs = []\n",
    "\t\tfor adj_list in self.adj_lists:\n",
    "\t\t\tto_neighs.append([set(adj_list[int(node)]) for node in nodes])\n",
    "\n",
    "\t\t# find unique nodes and their neighbors used in current batch\n",
    "\t\tunique_nodes = set.union(set.union(*to_neighs[0]), set.union(*to_neighs[1]),\n",
    "\t\t\t\t\t\t\t\t set.union(*to_neighs[2], set(nodes)))\n",
    "\n",
    "\t\t# calculate label-aware scores\n",
    "\t\tif self.cuda:\n",
    "\t\t\tbatch_features = self.features(torch.cuda.LongTensor(list(unique_nodes)))\n",
    "\t\telse:\n",
    "\t\t\tbatch_features = self.features(torch.LongTensor(list(unique_nodes)))\n",
    "\t\tbatch_scores = self.label_clf(batch_features)\n",
    "\t\tid_mapping = {node_id: index for node_id, index in zip(unique_nodes, range(len(unique_nodes)))}\n",
    "\n",
    "\t\t# the label-aware scores for current batch of nodes\n",
    "\t\tcenter_scores = batch_scores[itemgetter(*nodes)(id_mapping), :]\n",
    "\n",
    "\t\t# get neighbor node id list for each batch node and relation\n",
    "\t\tr1_list = [list(to_neigh) for to_neigh in to_neighs[0]]\n",
    "\t\tr2_list = [list(to_neigh) for to_neigh in to_neighs[1]]\n",
    "\t\tr3_list = [list(to_neigh) for to_neigh in to_neighs[2]]\n",
    "\n",
    "\t\t# assign label-aware scores to neighbor nodes for each batch node and relation\n",
    "\t\tr1_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r1_list]\n",
    "\t\tr2_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r2_list]\n",
    "\t\tr3_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r3_list]\n",
    "\n",
    "\t\t# count the number of neighbors kept for aggregation for each batch node and relation\n",
    "\t\tr1_sample_num_list = [math.ceil(len(neighs) * self.thresholds[0]) for neighs in r1_list]\n",
    "\t\tr2_sample_num_list = [math.ceil(len(neighs) * self.thresholds[1]) for neighs in r2_list]\n",
    "\t\tr3_sample_num_list = [math.ceil(len(neighs) * self.thresholds[2]) for neighs in r3_list]\n",
    "\n",
    "\t\t# intra-aggregation steps for each relation\n",
    "\t\t# Eq. (8) in the paper\n",
    "\t\tr1_feats, r1_scores = self.intra_agg1.forward(nodes, r1_list, center_scores, r1_scores, r1_sample_num_list)\n",
    "\t\tr2_feats, r2_scores = self.intra_agg2.forward(nodes, r2_list, center_scores, r2_scores, r2_sample_num_list)\n",
    "\t\tr3_feats, r3_scores = self.intra_agg3.forward(nodes, r3_list, center_scores, r3_scores, r3_sample_num_list)\n",
    "\n",
    "\t\t# concat the intra-aggregated embeddings from each relation\n",
    "\t\tneigh_feats = torch.cat((r1_feats, r2_feats, r3_feats), dim=0)\n",
    "\n",
    "\t\t# get features or embeddings for batch nodes\n",
    "\t\tif self.cuda and isinstance(nodes, list):\n",
    "\t\t\tindex = torch.LongTensor(nodes).cuda()\n",
    "\t\telse:\n",
    "\t\t\tindex = torch.LongTensor(nodes)\n",
    "\t\tself_feats = self.features(index)\n",
    "\n",
    "\t\t# number of nodes in a batch\n",
    "\t\tn = len(nodes)\n",
    "\n",
    "\t\t# inter-relation aggregation steps\n",
    "\t\t# Eq. (9) in the paper\n",
    "\t\t# if self.inter == 'Att':\n",
    "\t\t# \t# 1) CARE-Att Inter-relation Aggregator\n",
    "\t\t# \tcombined, attention = att_inter_agg(len(self.adj_lists), self.leakyrelu, self_feats, neigh_feats, self.embed_dim,\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\tself.weight, self.a, n, self.dropout, self.training, self.cuda)\n",
    "\t\t# elif self.inter == 'Weight':\n",
    "\t\t# \t# 2) CARE-Weight Inter-relation Aggregator\n",
    "\t\t# \tcombined = weight_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, self.alpha, n, self.cuda)\n",
    "\t\t# \tgem_weights = F.softmax(torch.sum(self.alpha, dim=0), dim=0).tolist()\n",
    "\t\t# \tif train_flag:\n",
    "\t\t# \t\tprint(f'Weights: {gem_weights}')\n",
    "\t\t# elif self.inter == 'Mean':\n",
    "\t\t# \t# 3) CARE-Mean Inter-relation Aggregator\n",
    "\t\t# \tcombined = mean_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, n, self.cuda)\n",
    "\t\tif self.inter == 'GNN':\n",
    "\t\t\t# 4) CARE-GNN Inter-relation Aggregator\n",
    "\t\t\tcombined = threshold_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, self.thresholds, n, self.cuda)\n",
    "\n",
    "\t\t# the reinforcement learning module\n",
    "\t\tif self.RL and train_flag:\n",
    "\t\t\trelation_scores, rewards, thresholds, stop_flag = RLModule([r1_scores, r2_scores, r3_scores],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   self.relation_score_log, labels, self.thresholds,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   self.batch_num, self.step_size)\n",
    "\t\t\tself.thresholds = thresholds\n",
    "\t\t\tself.RL = stop_flag\n",
    "\t\t\tself.relation_score_log.append(relation_scores)\n",
    "\t\t\tself.thresholds_log.append(self.thresholds)\n",
    "\n",
    "\t\treturn combined, center_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bdaec",
   "metadata": {},
   "source": [
    "### Instra Relation Aggregator with LeakyReLU (Proposed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad82239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntraAgg_leaky(nn.Module):\n",
    "\n",
    "\tdef __init__(self, features, feat_dim, cuda=False):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize the intra-relation aggregator\n",
    "\t\t:param features: the input node features or embeddings for all nodes\n",
    "\t\t:param feat_dim: the input dimension\n",
    "\t\t:param cuda: whether to use GPU\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(IntraAgg_leaky, self).__init__()\n",
    "\n",
    "\t\tself.features = features\n",
    "\t\tself.cuda = cuda\n",
    "\t\tself.feat_dim = feat_dim\n",
    "\n",
    "\tdef forward(self, nodes, to_neighs_list, batch_scores, neigh_scores, sample_list):\n",
    "\t\t\"\"\"\n",
    "\t\tCode partially from https://github.com/williamleif/graphsage-simple/\n",
    "\t\t:param nodes: list of nodes in a batch\n",
    "\t\t:param to_neighs_list: neighbor node id list for each batch node in one relation\n",
    "\t\t:param batch_scores: the label-aware scores of batch nodes\n",
    "\t\t:param neigh_scores: the label-aware scores 1-hop neighbors each batch node in one relation\n",
    "\t\t:param sample_list: the number of neighbors kept for each batch node in one relation\n",
    "\t\t:return to_feats: the aggregated embeddings of batch nodes neighbors in one relation\n",
    "\t\t:return samp_scores: the average neighbor distances for each relation after filtering\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# filer neighbors under given relation\n",
    "\t\tsamp_neighs, samp_scores = filter_neighs_ada_threshold(batch_scores, neigh_scores, to_neighs_list, sample_list)\n",
    "\n",
    "\t\t# find the unique nodes among batch nodes and the filtered neighbors\n",
    "\t\tunique_nodes_list = list(set.union(*samp_neighs))\n",
    "\t\tunique_nodes = {n: i for i, n in enumerate(unique_nodes_list)}\n",
    "\n",
    "\t\t# intra-relation aggregation only with sampled neighbors\n",
    "\t\tmask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
    "\t\tcolumn_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
    "\t\trow_indices = [i for i in range(len(samp_neighs)) for _ in range(len(samp_neighs[i]))]\n",
    "\t\tmask[row_indices, column_indices] = 1\n",
    "\t\tif self.cuda:\n",
    "\t\t\tmask = mask.cuda()\n",
    "\t\tnum_neigh = mask.sum(1, keepdim=True)\n",
    "\t\tmask = mask.div(num_neigh)\n",
    "\t\tif self.cuda:\n",
    "\t\t\tembed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())\n",
    "\t\telse:\n",
    "\t\t\tembed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
    "\t\tto_feats = mask.mm(embed_matrix)\n",
    "\t\t# to_feats = F.relu(to_feats)\n",
    "\t\tto_feats = nn.LeakyReLU(0.2)(to_feats) # Proposed Leakly Relu Activtion eqn 8\n",
    "\t\treturn to_feats, samp_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc8af5",
   "metadata": {},
   "source": [
    "### Reinforcement Learning Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLModule(scores, scores_log, labels, thresholds, batch_num, step_size):\n",
    "\t\"\"\"\n",
    "\tThe reinforcement learning module.\n",
    "\tIt updates the neighbor filtering threshold for each relation based\n",
    "\ton the average neighbor distances between two consecutive epochs.\n",
    "\t:param scores: the neighbor nodes label-aware scores for each relation\n",
    "\t:param scores_log: a list stores the relation average distances for each batch\n",
    "\t:param labels: the batch node labels used to select positive nodes\n",
    "\t:param thresholds: the current neighbor filtering thresholds for each relation\n",
    "\t:param batch_num: numbers batches in an epoch\n",
    "\t:param step_size: the RL action step size\n",
    "\t:return relation_scores: the relation average distances for current batch\n",
    "\t:return rewards: the reward for given thresholds in current epoch\n",
    "\t:return new_thresholds: the new filtering thresholds updated according to the rewards\n",
    "\t:return stop_flag: the RL terminal condition flag\n",
    "\t\"\"\"\n",
    "\n",
    "\trelation_scores = []\n",
    "\tstop_flag = True\n",
    "\n",
    "\t# only compute the average neighbor distances for positive nodes\n",
    "\tpos_index = (labels == 1).nonzero().tolist()\n",
    "\tpos_index = [i[0] for i in pos_index]\n",
    "\n",
    "\t# compute average neighbor distances for each relation\n",
    "\tfor score in scores:\n",
    "\t\tpos_scores = itemgetter(*pos_index)(score)\n",
    "\t\tneigh_count = sum([1 if isinstance(i, float) else len(i) for i in pos_scores])\n",
    "\t\tpos_sum = [i if isinstance(i, float) else sum(i) for i in pos_scores]\n",
    "\t\trelation_scores.append(sum(pos_sum) / neigh_count)\n",
    "\n",
    "\tif len(scores_log) % batch_num != 0 or len(scores_log) < 2 * batch_num:\n",
    "\t\t# do not call RL module within the epoch or within the first two epochs\n",
    "\t\trewards = [0, 0, 0]\n",
    "\t\tnew_thresholds = thresholds\n",
    "\telse:\n",
    "\t\t# update thresholds according to average scores in last epoch\n",
    "\t\t# Eq.(5) in the paper\n",
    "\t\tprevious_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-2 * batch_num:-batch_num])]\n",
    "\t\tcurrent_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-batch_num:])]\n",
    "\n",
    "\t\t# compute reward for each relation and update the thresholds according to reward\n",
    "\t\t# Eq. (6) in the paper\n",
    "\t\trewards = [1 if previous_epoch_scores[i] - s >= 0 else -1 for i, s in enumerate(current_epoch_scores)]\n",
    "\t\tnew_thresholds = [thresholds[i] + step_size if r == 1 else thresholds[i] - step_size for i, r in enumerate(rewards)]\n",
    "\n",
    "\t\t# avoid overflow\n",
    "\t\tnew_thresholds = [0.999 if i > 1 else i for i in new_thresholds]\n",
    "\t\tnew_thresholds = [0.001 if i < 0 else i for i in new_thresholds]\n",
    "\n",
    "\t\tprint(f'epoch scores: {current_epoch_scores}')\n",
    "\t\tprint(f'rewards: {rewards}')\n",
    "\t\tprint(f'thresholds: {new_thresholds}')\n",
    "\n",
    "\treturn relation_scores, rewards, new_thresholds, stop_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f612b",
   "metadata": {},
   "source": [
    "### Filter neighbors from label predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cba04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_neighs_ada_threshold(center_scores, neigh_scores, neighs_list, sample_list):\n",
    "\t\"\"\"\n",
    "\tFilter neighbors according label predictor result with adaptive thresholds\n",
    "\t:param center_scores: the label-aware scores of batch nodes\n",
    "\t:param neigh_scores: the label-aware scores 1-hop neighbors each batch node in one relation\n",
    "\t:param neighs_list: neighbor node id list for each batch node in one relation\n",
    "\t:param sample_list: the number of neighbors kept for each batch node in one relation\n",
    "\t:return samp_neighs: the neighbor indices and neighbor simi scores\n",
    "\t:return samp_scores: the average neighbor distances for each relation after filtering\n",
    "\t\"\"\"\n",
    "\n",
    "\tsamp_neighs = []\n",
    "\tsamp_scores = []\n",
    "\tfor idx, center_score in enumerate(center_scores):\n",
    "\t\tcenter_score = center_scores[idx][0]\n",
    "\t\tneigh_score = neigh_scores[idx][:, 0].view(-1, 1)\n",
    "\t\tcenter_score = center_score.repeat(neigh_score.size()[0], 1)\n",
    "\t\tneighs_indices = neighs_list[idx]\n",
    "\t\tnum_sample = sample_list[idx]\n",
    "\n",
    "\t\t# compute the L1-distance of batch nodes and their neighbors\n",
    "\t\t# Eq. (2) in paper\n",
    "\t\tscore_diff = torch.abs(center_score - neigh_score).squeeze()\n",
    "\t\tsorted_scores, sorted_indices = torch.sort(score_diff, dim=0, descending=False)\n",
    "\t\tselected_indices = sorted_indices.tolist()\n",
    "\n",
    "\t\t# top-p sampling according to distance ranking and thresholds\n",
    "\t\t# Section 3.3.1 in paper\n",
    "\t\tif len(neigh_scores[idx]) > num_sample + 1:\n",
    "\t\t\tselected_neighs = [neighs_indices[n] for n in selected_indices[:num_sample]]\n",
    "\t\t\tselected_scores = sorted_scores.tolist()[:num_sample]\n",
    "\t\telse:\n",
    "\t\t\tselected_neighs = neighs_indices\n",
    "\t\t\tselected_scores = score_diff.tolist()\n",
    "\t\t\tif isinstance(selected_scores, float):\n",
    "\t\t\t\tselected_scores = [selected_scores]\n",
    "\n",
    "\t\tsamp_neighs.append(set(selected_neighs))\n",
    "\t\tsamp_scores.append(selected_scores)\n",
    "\n",
    "\treturn samp_neighs, samp_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba3397",
   "metadata": {},
   "source": [
    "### CARE-GNN inter-relation aggregator using LeakyReLU (Proposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_inter_agg(num_relations, self_feats, neigh_feats, embed_dim, weight, threshold, n, cuda):\n",
    "\t\"\"\"\n",
    "\tCARE-GNN inter-relation aggregator\n",
    "\tEq. (9) in the paper use Leaky Relu instread of Relu\n",
    "\t:param num_relations: number of relations in the graph\n",
    "\t:param self_feats: batch nodes features or embeddings\n",
    "\t:param neigh_feats: intra-relation aggregated neighbor embeddings for each relation\n",
    "\t:param embed_dim: the dimension of output embedding\n",
    "\t:param weight: parameter used to transform node embeddings before inter-relation aggregation\n",
    "\t:param threshold: the neighbor filtering thresholds used as aggregating weights\n",
    "\t:param n: number of nodes in a batch\n",
    "\t:param cuda: whether use GPU\n",
    "\t:return: inter-relation aggregated node embeddings\n",
    "\t\"\"\"\n",
    "\n",
    "\t# transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
    "\tcenter_h = torch.mm(self_feats, weight)\n",
    "\tneigh_h = torch.mm(neigh_feats, weight)\n",
    "\n",
    "\t# initialize the final neighbor embedding\n",
    "\tif cuda:\n",
    "\t\taggregated = torch.zeros(size=(n, embed_dim)).cuda()\n",
    "\telse:\n",
    "\t\taggregated = torch.zeros(size=(n, embed_dim))\n",
    "\n",
    "\t# add weighted neighbor embeddings in each relation together\n",
    "\tfor r in range(num_relations):\n",
    "\t\taggregated += neigh_h[r * n:(r + 1) * n, :] * threshold[r]\n",
    "\n",
    "\t# sum aggregated neighbor embedding and batch node embedding\n",
    "\t# feed them to activation function\n",
    "\t# combined = F.relu(center_h + aggregated)\n",
    "\tcombined = nn.LeakyReLU(0.2)(center_h + aggregated) # Proposed Leakly Relu Activtion eqn 9\n",
    "\n",
    "\treturn combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2edc6",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaa829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
